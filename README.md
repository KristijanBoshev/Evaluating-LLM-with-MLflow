# Evaluating Fine-Tuned LLM with MLflow and Dagshub

This is the way to go if you want to evaluate your fine-tuned Large Language Model (LLM)!

I'm using MLflow to track and manage my experiments, and Dagshub to visualize and overview the results. However, please note that this repository is for testing purposes only, as I'm currently experimenting with the GPT-3.5 model.
